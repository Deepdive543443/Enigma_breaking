{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from model import cp_2_k_mask, cp_2_k_onnx\n",
    "from config import args\n",
    "from dataset import Enigma_simulate_c_2_p, Enigma_simulate_cp_2_k_limited, Enigma_simulate_cp_2_k\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copying the compiled weight to regular models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 27408974\n"
     ]
    },
    {
     "data": {
      "text/plain": "cp_2_k_mask(\n  (networks): ModuleList(\n    (0): RNN_encoder(\n      (enc): LSTM(512, 512, num_layers=2, dropout=0.2, bidirectional=True)\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (1): TransformerEncoder(\n      (layers): ModuleList(\n        (0-1): 2 x TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n          )\n          (linear1): Linear(in_features=1024, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.2, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=1024, bias=True)\n          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.2, inplace=False)\n          (dropout2): Dropout(p=0.2, inplace=False)\n        )\n      )\n    )\n  )\n  (linear_projectors): Linear(in_features=1024, out_features=78, bias=True)\n  (emb): Linear(in_features=52, out_features=512, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained model's weights and config\n",
    "ckpt = torch.load('CP2K_RNN_ENC_ckpt.pt')\n",
    "ckpt_args = ckpt['args']\n",
    "\n",
    "# Initialize new model by configs\n",
    "model = cp_2_k_mask(args=ckpt_args, out_channels=26)\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "\n",
    "# Load weights, calculate the number of parameters\n",
    "weights = []\n",
    "num_param = 0\n",
    "for k, v in ckpt['weights'].items():\n",
    "    weights.append(v)\n",
    "    num_param += np.prod(v.shape)\n",
    "print(f\"Parameters: {num_param}\")\n",
    "\n",
    "# Copying weights from compile model to new model\n",
    "for idx, (k, v) in enumerate(model.state_dict().items()):\n",
    "    # We have to copying like this, I am so confused\n",
    "    v *= 0\n",
    "    v += weights[idx].detach()\n",
    "\n",
    "# Set the model to evaluate mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Running a mini batch of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([30, 512, 52]) [seq, batch, feats]\n",
      "Target shape: torch.Size([3, 30, 512])  [rotor, seq, batch]\n",
      "Mask shape: torch.Size([512, 30])  [batch, seq]\n",
      "Output shape: torch.Size([3, 30, 512, 26])  [rotor, seq, batch, feats]\n",
      "Acc: 0.9993489980697632\n"
     ]
    }
   ],
   "source": [
    "dataset = Enigma_simulate_cp_2_k_limited(args=args)\n",
    "dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=512,\n",
    "        collate_fn=dataset.collate_fn_padding,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets, masks = next(data_iter)\n",
    "inputs, targets, masks = inputs.to('cuda'), targets.to('cuda'), masks.to('cuda')\n",
    "\n",
    "outputs = model(inputs, masks)\n",
    "\n",
    "print(f\"Input shape: {inputs.shape} {'[seq, batch, feats]'}\\n\"\n",
    "          f\"Target shape: {targets.shape}  {'[rotor, seq, batch]'}\\n\"\n",
    "          f\"Mask shape: {masks.shape}  {'[batch, seq]'}\\n\"\n",
    "          f\"Output shape: {outputs.shape}  {'[rotor, seq, batch, feats]'}\")\n",
    "\n",
    "true_positive = 0\n",
    "samples = 0\n",
    "\n",
    "outputs_indices = torch.argmax(outputs, dim=-1) # -> [rotor, seq, batch]\n",
    "for rotor in range(outputs_indices.shape[0]):\n",
    "    mask = outputs_indices[rotor][~masks.T] == targets[rotor][~masks.T]\n",
    "    true_positive += mask.sum()\n",
    "    samples += math.prod(mask.shape)\n",
    "\n",
    "print(f\"Acc: {true_positive / samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: AES\n"
     ]
    }
   ],
   "source": [
    "# Make prediction based on user's inputs( Results should be \"AES\")\n",
    "from dataset import cipher_plain_text_2_tensor\n",
    "inputs, masks = cipher_plain_text_2_tensor('VMPDTAJYTXDZNEFOSOTPJOYSMO', 'WEARETHECHAMPIONANDTHEBEST') # Predict on usr inputs\n",
    "inputs, masks = inputs.to('cuda'), masks.to('cuda')\n",
    "\n",
    "\n",
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs, masks).argmax(dim=-1).squeeze(-1) # -> shape [rotor, seq]\n",
    "\n",
    "# print the prediction at the first postion, which is the initial states\n",
    "print(f\"Prediction: {chr(ord('A') + outputs[0, 0])}\"\n",
    "      f\"{chr(ord('A') + outputs[1, 0])}\"\n",
    "      f\"{chr(ord('A') + outputs[2, 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 27408974\n",
      "Input shape: torch.Size([30, 1, 52]) [seq, batch, feats]\n",
      "Target shape: torch.Size([3, 30, 1])  [rotor, seq, batch]\n",
      "Mask shape: torch.Size([1, 30])  [batch, seq]\n",
      "Output shape: torch.Size([3, 30, 1, 26])  [rotor, seq, batch, feats]\n",
      "Acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\83577\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4476: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 1 ERROR ========================\n",
      "ERROR: missing-standard-symbolic-function\n",
      "=========================================\n",
      "Exporting the operator 'aten::unflatten' to ONNX opset version 14 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues.\n",
      "None\n",
      "<Set verbose=True to see more details>\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnsupportedOperatorError",
     "evalue": "Exporting the operator 'aten::unflatten' to ONNX opset version 14 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnsupportedOperatorError\u001B[0m                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 54\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAcc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrue_positive\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39msamples\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     53\u001B[0m \u001B[38;5;66;03m# Export onnx model\u001B[39;00m\n\u001B[1;32m---> 54\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43monnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43monnx_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseq5-45-large.onnx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput_1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;66;03m# Load and verify onnx model\u001B[39;00m\n\u001B[0;32m     63\u001B[0m ort_session \u001B[38;5;241m=\u001B[39m onnxruntime\u001B[38;5;241m.\u001B[39mInferenceSession(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseq5-45-large.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\utils.py:506\u001B[0m, in \u001B[0;36mexport\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001B[0m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;129m@_beartype\u001B[39m\u001B[38;5;241m.\u001B[39mbeartype\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexport\u001B[39m(\n\u001B[0;32m    190\u001B[0m     model: Union[torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule, torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mScriptModule, torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mScriptFunction],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    206\u001B[0m     export_modules_as_functions: Union[\u001B[38;5;28mbool\u001B[39m, Collection[Type[torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    207\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001B[39;00m\n\u001B[0;32m    209\u001B[0m \n\u001B[0;32m    210\u001B[0m \u001B[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    503\u001B[0m \u001B[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001B[39;00m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 506\u001B[0m     \u001B[43m_export\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[43m        \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    512\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    513\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    514\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    515\u001B[0m \u001B[43m        \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    516\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    521\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\utils.py:1548\u001B[0m, in \u001B[0;36m_export\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001B[0m\n\u001B[0;32m   1545\u001B[0m     dynamic_axes \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m   1546\u001B[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001B[1;32m-> 1548\u001B[0m graph, params_dict, torch_out \u001B[38;5;241m=\u001B[39m \u001B[43m_model_to_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1549\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1550\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1551\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1552\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1553\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1554\u001B[0m \u001B[43m    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1555\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_do_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1556\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfixed_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1557\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1558\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1559\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1561\u001B[0m \u001B[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001B[39;00m\n\u001B[0;32m   1562\u001B[0m defer_weight_export \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1563\u001B[0m     export_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _exporter_states\u001B[38;5;241m.\u001B[39mExportTypes\u001B[38;5;241m.\u001B[39mPROTOBUF_FILE\n\u001B[0;32m   1564\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\utils.py:1117\u001B[0m, in \u001B[0;36m_model_to_graph\u001B[1;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001B[0m\n\u001B[0;32m   1114\u001B[0m params_dict \u001B[38;5;241m=\u001B[39m _get_named_param_dict(graph, params)\n\u001B[0;32m   1116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1117\u001B[0m     graph \u001B[38;5;241m=\u001B[39m \u001B[43m_optimize_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1118\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1119\u001B[0m \u001B[43m        \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1120\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_disable_torch_constant_prop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_disable_torch_constant_prop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfixed_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1122\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1123\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1124\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1125\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodule\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1126\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1128\u001B[0m     torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch IR graph at exception: \u001B[39m\u001B[38;5;124m\"\u001B[39m, graph)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\utils.py:665\u001B[0m, in \u001B[0;36m_optimize_graph\u001B[1;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001B[0m\n\u001B[0;32m    662\u001B[0m     _C\u001B[38;5;241m.\u001B[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001B[0;32m    663\u001B[0m _C\u001B[38;5;241m.\u001B[39m_jit_pass_onnx_lint(graph)\n\u001B[1;32m--> 665\u001B[0m graph \u001B[38;5;241m=\u001B[39m \u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jit_pass_onnx\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    666\u001B[0m _C\u001B[38;5;241m.\u001B[39m_jit_pass_onnx_lint(graph)\n\u001B[0;32m    667\u001B[0m _C\u001B[38;5;241m.\u001B[39m_jit_pass_lint(graph)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\utils.py:1901\u001B[0m, in \u001B[0;36m_run_symbolic_function\u001B[1;34m(graph, block, node, inputs, env, operator_export_type)\u001B[0m\n\u001B[0;32m   1897\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m namespace \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monnx\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1898\u001B[0m         \u001B[38;5;66;03m# Clone node to trigger ONNX shape inference\u001B[39;00m\n\u001B[0;32m   1899\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m graph_context\u001B[38;5;241m.\u001B[39mop(op_name, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mattrs, outputs\u001B[38;5;241m=\u001B[39mnode\u001B[38;5;241m.\u001B[39moutputsSize())  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m-> 1901\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mUnsupportedOperatorError(\n\u001B[0;32m   1902\u001B[0m         symbolic_function_name,\n\u001B[0;32m   1903\u001B[0m         opset_version,\n\u001B[0;32m   1904\u001B[0m         symbolic_function_group\u001B[38;5;241m.\u001B[39mget_min_supported()\n\u001B[0;32m   1905\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m symbolic_function_group\n\u001B[0;32m   1906\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1907\u001B[0m     )\n\u001B[0;32m   1909\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m:\n\u001B[0;32m   1910\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m operator_export_type \u001B[38;5;241m==\u001B[39m _C_onnx\u001B[38;5;241m.\u001B[39mOperatorExportTypes\u001B[38;5;241m.\u001B[39mONNX_FALLTHROUGH:\n",
      "\u001B[1;31mUnsupportedOperatorError\u001B[0m: Exporting the operator 'aten::unflatten' to ONNX opset version 14 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues."
     ]
    }
   ],
   "source": [
    "# Transfer to onnx\n",
    "import onnx, onnxruntime\n",
    "onnx_model = cp_2_k_onnx(args=ckpt_args, out_channels=26)\n",
    "onnx_model.to('cuda')\n",
    "onnx_model.eval()\n",
    "\n",
    "# Load weights, calculate the number of parameters\n",
    "weights = []\n",
    "num_param = 0\n",
    "for k, v in ckpt['weights'].items():\n",
    "    weights.append(v)\n",
    "    num_param += np.prod(v.shape)\n",
    "print(f\"Parameters: {num_param}\")\n",
    "\n",
    "# Copying weights from compile model to new model\n",
    "for idx, (k, v) in enumerate(onnx_model.state_dict().items()):\n",
    "    # We have to copying like this, I am so confused\n",
    "    v *= 0\n",
    "    v += weights[idx].detach()\n",
    "\n",
    "# Testing the pre-export model in batch size 1\n",
    "dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=1,\n",
    "        collate_fn=dataset.collate_fn_padding,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "# Get samples for dataset\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets, masks = next(data_iter)\n",
    "inputs, targets, masks = inputs.to('cuda'), targets.to('cuda'), masks.to('cuda')\n",
    "\n",
    "outputs = onnx_model(inputs)\n",
    "\n",
    "print(f\"Input shape: {inputs.shape} {'[seq, batch, feats]'}\\n\"\n",
    "      f\"Target shape: {targets.shape}  {'[rotor, seq, batch]'}\\n\"\n",
    "      f\"Mask shape: {masks.shape}  {'[batch, seq]'}\\n\"\n",
    "      f\"Output shape: {outputs.shape}  {'[rotor, seq, batch, feats]'}\")\n",
    "\n",
    "\n",
    "true_positive = 0\n",
    "samples = 0\n",
    "\n",
    "outputs_indices = torch.argmax(outputs, dim=-1) # -> [rotor, seq, batch]\n",
    "for rotor in range(outputs_indices.shape[0]):\n",
    "    mask = outputs_indices[rotor][~masks.T] == targets[rotor][~masks.T]\n",
    "    true_positive += mask.sum()\n",
    "    samples += math.prod(mask.shape)\n",
    "\n",
    "print(f\"Acc: {true_positive / samples}\")\n",
    "\n",
    "# Export onnx model\n",
    "torch.onnx.export(\n",
    "    onnx_model,\n",
    "    args=inputs,\n",
    "    f=\"seq5-45-large.onnx\",\n",
    "    input_names=[\"input_1\"],\n",
    "    output_names=[\"output1\"]\n",
    ")\n",
    "\n",
    "# Load and verify onnx model\n",
    "ort_session = onnxruntime.InferenceSession(\"seq5-45-large.onnx\")\n",
    "inputs, _ = cipher_plain_text_2_tensor('WEARETHECHAMPIONANDTHEBESTPLAY', 'VMPDTAJYTXDZNEFOSOTPJOYSMOEBNX')\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {\"input_1\": np.array(inputs)},\n",
    ")\n",
    "\n",
    "outputs = outputs[0].argmax(axis=-1).reshape(outputs[0].shape[0], outputs[0].shape[1])\n",
    "print(outputs.shape)\n",
    "print(f\"Onnx Prediction: {chr(ord('A') + outputs[0, 0])}\"\n",
    "      f\"{chr(ord('A') + outputs[1, 0])}\"\n",
    "      f\"{chr(ord('A') + outputs[2, 0])}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Length: 5: 100%|██████████| 35/35 [00:06<00:00,  5.63it/s, Acc: 0.12045592069625854]\n",
      "Length: 6: 100%|██████████| 35/35 [00:06<00:00,  5.02it/s, Acc: 0.1898564249277115] \n",
      "Length: 7: 100%|██████████| 35/35 [00:07<00:00,  4.76it/s, Acc: 0.3023237884044647] \n",
      "Length: 8: 100%|██████████| 35/35 [00:07<00:00,  4.68it/s, Acc: 0.4520321488380432] \n",
      "Length: 9: 100%|██████████| 35/35 [00:07<00:00,  4.54it/s, Acc: 0.6056374907493591]\n",
      "Length: 10: 100%|██████████| 35/35 [00:07<00:00,  4.42it/s, Acc: 0.729058563709259] \n",
      "Length: 11: 100%|██████████| 35/35 [00:08<00:00,  4.28it/s, Acc: 0.8160499334335327]\n",
      "Length: 12: 100%|██████████| 35/35 [00:08<00:00,  4.10it/s, Acc: 0.877768874168396] \n",
      "Length: 13: 100%|██████████| 35/35 [00:08<00:00,  4.05it/s, Acc: 0.9175747632980347]\n",
      "Length: 14: 100%|██████████| 35/35 [00:08<00:00,  3.98it/s, Acc: 0.9459916949272156]\n",
      "Length: 15: 100%|██████████| 35/35 [00:08<00:00,  4.05it/s, Acc: 0.9669827818870544]\n",
      "Length: 16: 100%|██████████| 35/35 [00:09<00:00,  3.72it/s, Acc: 0.9804503917694092]\n",
      "Length: 17: 100%|██████████| 35/35 [00:09<00:00,  3.81it/s, Acc: 0.9875883460044861]\n",
      "Length: 18: 100%|██████████| 35/35 [00:09<00:00,  3.54it/s, Acc: 0.9920482635498047]\n",
      "Length: 19: 100%|██████████| 35/35 [00:09<00:00,  3.53it/s, Acc: 0.9936186671257019]\n",
      "Length: 20: 100%|██████████| 35/35 [00:10<00:00,  3.48it/s, Acc: 0.995372474193573] \n",
      "Length: 21: 100%|██████████| 35/35 [00:10<00:00,  3.28it/s, Acc: 0.9963916540145874]\n",
      "Length: 22: 100%|██████████| 35/35 [00:10<00:00,  3.31it/s, Acc: 0.9970461130142212]\n",
      "Length: 23: 100%|██████████| 35/35 [00:10<00:00,  3.32it/s, Acc: 0.9974124431610107]\n",
      "Length: 24: 100%|██████████| 35/35 [00:10<00:00,  3.21it/s, Acc: 0.9977368116378784]\n",
      "Length: 25: 100%|██████████| 35/35 [00:11<00:00,  3.15it/s, Acc: 0.9981303811073303]\n",
      "Length: 26: 100%|██████████| 35/35 [00:12<00:00,  2.82it/s, Acc: 0.9983602166175842]\n",
      "Length: 27: 100%|██████████| 35/35 [00:11<00:00,  2.94it/s, Acc: 0.9987514019012451]\n",
      "Length: 28: 100%|██████████| 35/35 [00:12<00:00,  2.75it/s, Acc: 0.9989372491836548]\n",
      "Length: 29: 100%|██████████| 35/35 [00:11<00:00,  2.92it/s, Acc: 0.9990209937095642]\n",
      "Length: 30: 100%|██████████| 35/35 [00:12<00:00,  2.79it/s, Acc: 0.9990922212600708]\n",
      "Length: 31: 100%|██████████| 35/35 [00:12<00:00,  2.79it/s, Acc: 0.9991114139556885]\n",
      "Length: 32: 100%|██████████| 35/35 [00:12<00:00,  2.76it/s, Acc: 0.999163806438446] \n",
      "Length: 33: 100%|██████████| 35/35 [00:13<00:00,  2.52it/s, Acc: 0.9991856217384338]\n",
      "Length: 34: 100%|██████████| 35/35 [00:13<00:00,  2.65it/s, Acc: 0.999218761920929] \n",
      "Length: 35: 100%|██████████| 35/35 [00:13<00:00,  2.53it/s, Acc: 0.9992514252662659]\n",
      "Length: 36: 100%|██████████| 35/35 [00:13<00:00,  2.54it/s, Acc: 0.9992603063583374]\n",
      "Length: 37: 100%|██████████| 35/35 [00:14<00:00,  2.35it/s, Acc: 0.9992852807044983]\n",
      "Length: 38: 100%|██████████| 35/35 [00:16<00:00,  2.16it/s, Acc: 0.999313473701477] \n",
      "Length: 39: 100%|██████████| 35/35 [00:15<00:00,  2.30it/s, Acc: 0.9993258118629456]\n",
      "Length: 40: 100%|██████████| 35/35 [00:15<00:00,  2.25it/s, Acc: 0.9993447065353394]\n",
      "Length: 41: 100%|██████████| 35/35 [00:15<00:00,  2.30it/s, Acc: 0.9993584156036377]\n",
      "Length: 42: 100%|██████████| 35/35 [00:15<00:00,  2.27it/s, Acc: 0.9993761777877808]\n",
      "Length: 43: 100%|██████████| 35/35 [00:15<00:00,  2.23it/s, Acc: 0.9993929266929626]\n",
      "Length: 44: 100%|██████████| 35/35 [00:16<00:00,  2.17it/s, Acc: 0.9994062185287476]\n",
      "Length: 45: 100%|██████████| 35/35 [00:16<00:00,  2.15it/s, Acc: 0.9994236826896667]\n",
      "Length: 46: 100%|██████████| 35/35 [00:16<00:00,  2.09it/s, Acc: 0.9993805289268494]\n",
      "Length: 47: 100%|██████████| 35/35 [00:23<00:00,  1.48it/s, Acc: 0.9973123669624329]\n",
      "Length: 48: 100%|██████████| 35/35 [00:18<00:00,  1.90it/s, Acc: 0.9979477524757385]\n",
      "Length: 49: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s, Acc: 0.9950199127197266]\n",
      "Length: 50: 100%|██████████| 35/35 [00:18<00:00,  1.88it/s, Acc: 0.9848829507827759]\n"
     ]
    }
   ],
   "source": [
    "# Testint accuracy in different length\n",
    "testing_args = args\n",
    "results = {}\n",
    "\n",
    "\n",
    "for length in range(5, 51):\n",
    "    testing_args['SEQ_LENGTH'] = [length, length]\n",
    "    dataset = Enigma_simulate_cp_2_k_limited(args=testing_args, mode='test')\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=1024,\n",
    "        collate_fn=dataset.collate_fn_padding,\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # Tracking\n",
    "    true_positive = 0\n",
    "    samples = 0\n",
    "\n",
    "    bar = tqdm(dataloader, leave=True)\n",
    "    bar.set_description_str(f\"Length: {length}\")\n",
    "\n",
    "    for inputs, targets, masks in bar:\n",
    "        inputs, targets, masks = inputs.to('cuda'), targets.to('cuda'), masks.to('cuda')\n",
    "\n",
    "        # Making prediction\n",
    "        # with torch.cuda.amp.autocast():\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs, masks)\n",
    "\n",
    "            # Compute accuracy\n",
    "            outputs_indices = torch.argmax(outputs, dim=-1) # -> [rotor, seq, batch]\n",
    "            for rotor in range(outputs_indices.shape[0]):\n",
    "                mask = outputs_indices[rotor][~masks.T] == targets[rotor][~masks.T]\n",
    "                true_positive += mask.sum()\n",
    "                samples += math.prod(mask.shape)\n",
    "\n",
    "        # Set bar's postfix\n",
    "        bar.set_postfix_str(f\"Acc: {(true_positive / samples).item()}\")\n",
    "\n",
    "    # Output and record the result\n",
    "    results[length] = (true_positive / samples).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ploting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28\n",
      " 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50] [0.12045592 0.18985642 0.30232379 0.45203215 0.60563749 0.72905856\n",
      " 0.81604993 0.87776887 0.91757476 0.94599169 0.96698278 0.98045039\n",
      " 0.98758835 0.99204826 0.99361867 0.99537247 0.99639165 0.99704611\n",
      " 0.99741244 0.99773681 0.99813038 0.99836022 0.9987514  0.99893725\n",
      " 0.99902099 0.99909222 0.99911141 0.99916381 0.99918562 0.99921876\n",
      " 0.99925143 0.99926031 0.99928528 0.99931347 0.99932581 0.99934471\n",
      " 0.99935842 0.99937618 0.99939293 0.99940622 0.99942368 0.99938053\n",
      " 0.99731237 0.99794775 0.99501991 0.98488295]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 960x800 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = list(results.keys())\n",
    "y = list(results.values())\n",
    "\n",
    "x, y = np.array(x), np.array(y)\n",
    "print(x, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10), dpi=80)\n",
    "ax.bar(x,height=y)\n",
    "plt.title('Seq5-45-large', fontsize=15)\n",
    "ax.set_ylabel('Acc', fontsize=15)\n",
    "ax.set_xlabel('Length', fontsize=15)\n",
    "plt.show()\n",
    "# ax.plot(bins, y, '--')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}